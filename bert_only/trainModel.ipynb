{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cases = pickle.load(open(\"processedCases.pickle\", \"rb\"))\n",
    "\n",
    "justiceId = \"antonin_scalia\"\n",
    "\n",
    "justiceCases = [x for x in cases if justiceId in x[\"votes\"].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1830"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(justiceCases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2938"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'plantiff': 'United States',\n",
       " 'defendant': 'Cotton',\n",
       " 'question': \"Does the omission from a federal indictment of a fact that enhances the statutory maximum sentence justify a Court of Appeals' vacating the enhanced sentence, even though the defendant did not object in the trial court?\",\n",
       " 'facts': 'A federal grand jury returned an indictment charging Leonard defendant and others with conspiracy to distribute and to possess with intent to distribute a detectable amount of cocaine and cocaine base. After a jury convicted them, defendant and the others received a sentence based on the District Court\\'s finding of drug quantity of at least 50 grams of cocaine base, which implicated certain enhanced penalties. They did not object in the District Court to the fact that the sentences were based on a quantity not alleged in the indictment. While their appeal was pending, the U.S. Supreme Court decided, in Apprendi v. New Jersey, 530 U.S. 466, that \"other than the fact of a prior conviction, any fact that increases the penalty for a crime beyond the prescribed statutory maximum must be submitted to a jury, and proved beyond a reasonable doubt.\" In federal prosecutions, such facts must also be charged in the indictment. defendant and others then argued before the Court of Appeals that their sentences were invalid under Apprendi, because the drug quantity issue was neither alleged in the indictment nor submitted to the petit jury. The appellate court vacated the sentences on the ground that it had no jurisdiction to impose a sentence for an offense not charged in the indictment.',\n",
       " 'court': 'rehnquist10',\n",
       " 'winningParty': 'United States',\n",
       " 'inFavorPlantiff': True,\n",
       " 'votes': {'william_h_rehnquist': 'plantiff',\n",
       "  'john_paul_stevens': 'plantiff',\n",
       "  'sandra_day_oconnor': 'plantiff',\n",
       "  'antonin_scalia': 'plantiff',\n",
       "  'anthony_m_kennedy': 'plantiff',\n",
       "  'david_h_souter': 'plantiff',\n",
       "  'clarence_thomas': 'plantiff',\n",
       "  'ruth_bader_ginsburg': 'plantiff',\n",
       "  'stephen_g_breyer': 'plantiff'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "justiceCases[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"question\": x[\"question\"], \"facts\": x[\"facts\"], \"vote\": x[\"votes\"][justiceId]} for x in justiceCases]\n",
    "#data = [{\"question\": x[\"question\"], \"facts\": x[\"facts\"], \"vote\": x[\"inFavorPlantiff\"]} for x in cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>facts</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does the omission from a federal indictment of...</td>\n",
       "      <td>A federal grand jury returned an indictment ch...</td>\n",
       "      <td>plantiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does the ministerial exception, which prohibit...</td>\n",
       "      <td>Cheryl Perich filed a lawsuit against the plan...</td>\n",
       "      <td>plantiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there a conceivable rational basis justifyi...</td>\n",
       "      <td>Section 602(7)(B) of the Cable Communications ...</td>\n",
       "      <td>plantiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did the Constable's action infringe upon defen...</td>\n",
       "      <td>Ardith defendant was a clerical employee in th...</td>\n",
       "      <td>plantiff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does the Court of Federal Claims, under the In...</td>\n",
       "      <td>Under Public Law 86-392, the former Fort Apach...</td>\n",
       "      <td>plantiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Does the omission from a federal indictment of...   \n",
       "1  Does the ministerial exception, which prohibit...   \n",
       "2  Is there a conceivable rational basis justifyi...   \n",
       "3  Did the Constable's action infringe upon defen...   \n",
       "4  Does the Court of Federal Claims, under the In...   \n",
       "\n",
       "                                               facts      vote  \n",
       "0  A federal grand jury returned an indictment ch...  plantiff  \n",
       "1  Cheryl Perich filed a lawsuit against the plan...  plantiff  \n",
       "2  Section 602(7)(B) of the Cable Communications ...  plantiff  \n",
       "3  Ardith defendant was a clerical employee in th...  plantiff  \n",
       "4  Under Public Law 86-392, the former Fort Apach...  plantiff  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"question\"] + \" [SEP] \" + df[\"facts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = [1 if x == \"plantiff\" else 0 for x in df[\"vote\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>facts</th>\n",
       "      <th>vote</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does the omission from a federal indictment of...</td>\n",
       "      <td>A federal grand jury returned an indictment ch...</td>\n",
       "      <td>plantiff</td>\n",
       "      <td>Does the omission from a federal indictment of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Does the ministerial exception, which prohibit...</td>\n",
       "      <td>Cheryl Perich filed a lawsuit against the plan...</td>\n",
       "      <td>plantiff</td>\n",
       "      <td>Does the ministerial exception, which prohibit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is there a conceivable rational basis justifyi...</td>\n",
       "      <td>Section 602(7)(B) of the Cable Communications ...</td>\n",
       "      <td>plantiff</td>\n",
       "      <td>Is there a conceivable rational basis justifyi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did the Constable's action infringe upon defen...</td>\n",
       "      <td>Ardith defendant was a clerical employee in th...</td>\n",
       "      <td>plantiff</td>\n",
       "      <td>Did the Constable's action infringe upon defen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Does the Court of Federal Claims, under the In...</td>\n",
       "      <td>Under Public Law 86-392, the former Fort Apach...</td>\n",
       "      <td>plantiff</td>\n",
       "      <td>Does the Court of Federal Claims, under the In...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Does the omission from a federal indictment of...   \n",
       "1  Does the ministerial exception, which prohibit...   \n",
       "2  Is there a conceivable rational basis justifyi...   \n",
       "3  Did the Constable's action infringe upon defen...   \n",
       "4  Does the Court of Federal Claims, under the In...   \n",
       "\n",
       "                                               facts      vote  \\\n",
       "0  A federal grand jury returned an indictment ch...  plantiff   \n",
       "1  Cheryl Perich filed a lawsuit against the plan...  plantiff   \n",
       "2  Section 602(7)(B) of the Cable Communications ...  plantiff   \n",
       "3  Ardith defendant was a clerical employee in th...  plantiff   \n",
       "4  Under Public Law 86-392, the former Fort Apach...  plantiff   \n",
       "\n",
       "                                                text  label  \n",
       "0  Does the omission from a federal indictment of...      1  \n",
       "1  Does the ministerial exception, which prohibit...      1  \n",
       "2  Is there a conceivable rational basis justifyi...      1  \n",
       "3  Did the Constable's action infringe upon defen...      1  \n",
       "4  Does the Court of Federal Claims, under the In...      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1830.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.575956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label\n",
       "count  1830.000000\n",
       "mean      0.575956\n",
       "std       0.494332\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlpaueb/legal-bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(df[[\"text\", \"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 1830\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.69ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17.19ba/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512, add_special_tokens=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"nlpaueb/legal-bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test_trainer\", num_train_epochs=10, per_device_train_batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 1464\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1830\n",
      " 27%|██▋       | 500/1830 [02:34<06:53,  3.21it/s]Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6977, 'learning_rate': 3.633879781420765e-05, 'epoch': 2.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      " 55%|█████▍    | 1000/1830 [05:20<04:42,  2.94it/s]Saving model checkpoint to test_trainer/checkpoint-1000\n",
      "Configuration saved in test_trainer/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6939, 'learning_rate': 2.2677595628415303e-05, 'epoch': 5.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
      " 82%|████████▏ | 1500/1830 [08:11<01:52,  2.93it/s]Saving model checkpoint to test_trainer/checkpoint-1500\n",
      "Configuration saved in test_trainer/checkpoint-1500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6919, 'learning_rate': 9.016393442622952e-06, 'epoch': 8.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n",
      "100%|██████████| 1830/1830 [10:02<00:00,  2.89it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 1830/1830 [10:02<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 602.3004, 'train_samples_per_second': 24.307, 'train_steps_per_second': 3.038, 'train_loss': 0.6933009580184853, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1830, training_loss=0.6933009580184853, metrics={'train_runtime': 602.3004, 'train_samples_per_second': 24.307, 'train_steps_per_second': 3.038, 'train_loss': 0.6933009580184853, 'epoch': 10.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args, train_dataset=tokenized_datasets[\"train\"], eval_dataset=tokenized_datasets[\"test\"]\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits = eval_pred[0]\n",
    "    labels = eval_pred[1]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 366\n",
      "  Batch size = 8\n",
      " 98%|█████████▊| 45/46 [00:04<00:00,  8.71it/s]"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6010928961748634}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1670308 ,  0.14468601],\n",
       "       [-0.16703062,  0.1446866 ],\n",
       "       [-0.1670308 ,  0.14468594],\n",
       "       [-0.16703025,  0.14468557],\n",
       "       [-0.16703108,  0.14468566],\n",
       "       [-0.16703057,  0.14468575],\n",
       "       [-0.16703111,  0.14468518],\n",
       "       [-0.16703083,  0.14468575],\n",
       "       [-0.16703081,  0.14468549],\n",
       "       [-0.16703105,  0.1446856 ],\n",
       "       [-0.16703068,  0.14468612],\n",
       "       [-0.16703066,  0.14468548],\n",
       "       [-0.16703074,  0.1446858 ],\n",
       "       [-0.1670307 ,  0.1446859 ],\n",
       "       [-0.16703062,  0.144686  ],\n",
       "       [-0.16703127,  0.14468554],\n",
       "       [-0.1670307 ,  0.14468616],\n",
       "       [-0.16703083,  0.1446856 ],\n",
       "       [-0.16703063,  0.14468625],\n",
       "       [-0.16703087,  0.14468625],\n",
       "       [-0.16703041,  0.14468606],\n",
       "       [-0.16703083,  0.1446855 ],\n",
       "       [-0.16703068,  0.1446858 ],\n",
       "       [-0.16703005,  0.14468598],\n",
       "       [-0.1670307 ,  0.14468604],\n",
       "       [-0.16703066,  0.1446853 ],\n",
       "       [-0.16703106,  0.14468555],\n",
       "       [-0.16703047,  0.14468612],\n",
       "       [-0.1670303 ,  0.14468598],\n",
       "       [-0.16703044,  0.1446861 ],\n",
       "       [-0.16703011,  0.14468628],\n",
       "       [-0.16703077,  0.14468575],\n",
       "       [-0.16703023,  0.1446859 ],\n",
       "       [-0.1670306 ,  0.14468616],\n",
       "       [-0.16703013,  0.14468613],\n",
       "       [-0.16703062,  0.14468567],\n",
       "       [-0.16703099,  0.14468545],\n",
       "       [-0.16703023,  0.1446856 ],\n",
       "       [-0.16703051,  0.14468613],\n",
       "       [-0.16703023,  0.14468575],\n",
       "       [-0.16703117,  0.14468567],\n",
       "       [-0.16703081,  0.14468601],\n",
       "       [-0.16703017,  0.14468606],\n",
       "       [-0.16703115,  0.14468566],\n",
       "       [-0.16703089,  0.14468586],\n",
       "       [-0.16703066,  0.14468609],\n",
       "       [-0.16703038,  0.14468585],\n",
       "       [-0.16703044,  0.1446858 ],\n",
       "       [-0.16703069,  0.14468566],\n",
       "       [-0.16703068,  0.14468575],\n",
       "       [-0.1670305 ,  0.14468601],\n",
       "       [-0.1670309 ,  0.1446858 ],\n",
       "       [-0.1670302 ,  0.14468628],\n",
       "       [-0.16703075,  0.14468536],\n",
       "       [-0.16703114,  0.14468536],\n",
       "       [-0.16703017,  0.1446861 ],\n",
       "       [-0.16703041,  0.14468637],\n",
       "       [-0.16703086,  0.14468557],\n",
       "       [-0.16703054,  0.14468607],\n",
       "       [-0.16703095,  0.14468578],\n",
       "       [-0.1670307 ,  0.14468604],\n",
       "       [-0.1670306 ,  0.14468554],\n",
       "       [-0.16703054,  0.14468595],\n",
       "       [-0.16703056,  0.14468558],\n",
       "       [-0.16703036,  0.14468633],\n",
       "       [-0.16703053,  0.14468598],\n",
       "       [-0.1670308 ,  0.14468585],\n",
       "       [-0.16703056,  0.14468583],\n",
       "       [-0.16703057,  0.14468563],\n",
       "       [-0.167031  ,  0.1446859 ],\n",
       "       [-0.16703056,  0.14468588],\n",
       "       [-0.16703051,  0.14468625],\n",
       "       [-0.16703038,  0.14468631],\n",
       "       [-0.16703103,  0.14468594],\n",
       "       [-0.16703105,  0.14468573],\n",
       "       [-0.16703032,  0.14468598],\n",
       "       [-0.16703053,  0.14468616],\n",
       "       [-0.16703078,  0.1446857 ],\n",
       "       [-0.1670307 ,  0.14468572],\n",
       "       [-0.1670312 ,  0.14468554],\n",
       "       [-0.16703048,  0.14468636],\n",
       "       [-0.16703087,  0.14468597],\n",
       "       [-0.16702993,  0.14468655],\n",
       "       [-0.16703078,  0.14468573],\n",
       "       [-0.16703068,  0.144686  ],\n",
       "       [-0.16703068,  0.14468578],\n",
       "       [-0.16703041,  0.14468604],\n",
       "       [-0.16703051,  0.14468616],\n",
       "       [-0.16703115,  0.14468561],\n",
       "       [-0.167031  ,  0.14468566],\n",
       "       [-0.1670302 ,  0.14468569],\n",
       "       [-0.16703092,  0.14468521],\n",
       "       [-0.16703083,  0.1446855 ],\n",
       "       [-0.16703089,  0.14468607],\n",
       "       [-0.16703032,  0.14468625],\n",
       "       [-0.16703153,  0.14468546],\n",
       "       [-0.16703048,  0.14468634],\n",
       "       [-0.16703065,  0.1446861 ],\n",
       "       [-0.16703066,  0.14468585],\n",
       "       [-0.16703089,  0.14468603],\n",
       "       [-0.16703045,  0.14468586],\n",
       "       [-0.16703059,  0.14468583],\n",
       "       [-0.16703053,  0.14468595],\n",
       "       [-0.16703026,  0.14468636],\n",
       "       [-0.16703069,  0.14468594],\n",
       "       [-0.16703074,  0.14468592],\n",
       "       [-0.16703063,  0.1446863 ],\n",
       "       [-0.16703057,  0.14468558],\n",
       "       [-0.1670307 ,  0.14468557],\n",
       "       [-0.1670307 ,  0.14468554],\n",
       "       [-0.16703023,  0.14468624],\n",
       "       [-0.16703033,  0.1446859 ],\n",
       "       [-0.16703017,  0.14468583],\n",
       "       [-0.16703005,  0.1446858 ],\n",
       "       [-0.16703062,  0.14468595],\n",
       "       [-0.167031  ,  0.14468566],\n",
       "       [-0.16703095,  0.14468607],\n",
       "       [-0.16703078,  0.14468604],\n",
       "       [-0.16703045,  0.14468576],\n",
       "       [-0.16703086,  0.14468592],\n",
       "       [-0.16703041,  0.14468586],\n",
       "       [-0.16703026,  0.14468613],\n",
       "       [-0.16703026,  0.14468586],\n",
       "       [-0.16703081,  0.14468586],\n",
       "       [-0.16703095,  0.14468595],\n",
       "       [-0.16702965,  0.14468649],\n",
       "       [-0.16703068,  0.14468601],\n",
       "       [-0.16703044,  0.14468595],\n",
       "       [-0.16703077,  0.144686  ],\n",
       "       [-0.16703044,  0.1446861 ],\n",
       "       [-0.16703054,  0.14468619],\n",
       "       [-0.16703092,  0.1446859 ],\n",
       "       [-0.1670308 ,  0.14468578],\n",
       "       [-0.16703112,  0.14468575],\n",
       "       [-0.16703108,  0.1446857 ],\n",
       "       [-0.1670307 ,  0.14468579],\n",
       "       [-0.16703066,  0.1446858 ],\n",
       "       [-0.16703075,  0.14468598],\n",
       "       [-0.16703106,  0.14468578],\n",
       "       [-0.1670306 ,  0.1446859 ],\n",
       "       [-0.16703115,  0.14468554],\n",
       "       [-0.16703074,  0.14468561],\n",
       "       [-0.1670312 ,  0.14468564],\n",
       "       [-0.16703065,  0.14468563],\n",
       "       [-0.16703047,  0.14468616],\n",
       "       [-0.16703051,  0.14468604],\n",
       "       [-0.16703078,  0.14468554],\n",
       "       [-0.16703086,  0.14468566],\n",
       "       [-0.16703099,  0.14468592],\n",
       "       [-0.16703056,  0.14468607],\n",
       "       [-0.16702993,  0.14468552],\n",
       "       [-0.16703054,  0.14468634],\n",
       "       [-0.16703069,  0.1446861 ],\n",
       "       [-0.16703023,  0.14468563],\n",
       "       [-0.16703056,  0.144686  ],\n",
       "       [-0.1670302 ,  0.14468575],\n",
       "       [-0.16703056,  0.14468597],\n",
       "       [-0.16703044,  0.14468566],\n",
       "       [-0.16703008,  0.14468634],\n",
       "       [-0.16703063,  0.14468586],\n",
       "       [-0.16703026,  0.14468639],\n",
       "       [-0.16703092,  0.14468618],\n",
       "       [-0.16703074,  0.14468598],\n",
       "       [-0.16703074,  0.14468572],\n",
       "       [-0.16703074,  0.14468575],\n",
       "       [-0.16703121,  0.14468586],\n",
       "       [-0.16703045,  0.14468607],\n",
       "       [-0.16703065,  0.14468522],\n",
       "       [-0.16703077,  0.1446858 ],\n",
       "       [-0.16703063,  0.14468601],\n",
       "       [-0.16703044,  0.1446858 ],\n",
       "       [-0.16703077,  0.1446858 ],\n",
       "       [-0.16703084,  0.14468583],\n",
       "       [-0.16703098,  0.14468569],\n",
       "       [-0.16703074,  0.14468569],\n",
       "       [-0.16703059,  0.14468607],\n",
       "       [-0.16703074,  0.14468575],\n",
       "       [-0.16703096,  0.14468604],\n",
       "       [-0.1670298 ,  0.14468566],\n",
       "       [-0.16703056,  0.1446857 ],\n",
       "       [-0.16703072,  0.14468616],\n",
       "       [-0.16703093,  0.14468582],\n",
       "       [-0.16703045,  0.14468595],\n",
       "       [-0.1670305 ,  0.14468625],\n",
       "       [-0.16703098,  0.1446856 ],\n",
       "       [-0.1670308 ,  0.14468557],\n",
       "       [-0.16703074,  0.14468542],\n",
       "       [-0.16703054,  0.14468619],\n",
       "       [-0.16703033,  0.14468613],\n",
       "       [-0.1670303 ,  0.14468555],\n",
       "       [-0.16703032,  0.14468566],\n",
       "       [-0.16703017,  0.1446858 ],\n",
       "       [-0.16703074,  0.1446853 ],\n",
       "       [-0.16703054,  0.14468628],\n",
       "       [-0.16703075,  0.14468537],\n",
       "       [-0.1670308 ,  0.14468554],\n",
       "       [-0.16703077,  0.14468557],\n",
       "       [-0.16703092,  0.14468563],\n",
       "       [-0.16703048,  0.1446858 ],\n",
       "       [-0.1670309 ,  0.14468563],\n",
       "       [-0.16703002,  0.1446859 ],\n",
       "       [-0.16703011,  0.1446861 ],\n",
       "       [-0.16703057,  0.1446861 ],\n",
       "       [-0.16703111,  0.14468536],\n",
       "       [-0.1670305 ,  0.14468578],\n",
       "       [-0.16703095,  0.14468566],\n",
       "       [-0.16702975,  0.14468631],\n",
       "       [-0.16703057,  0.14468634],\n",
       "       [-0.16703086,  0.1446859 ],\n",
       "       [-0.16703065,  0.14468575],\n",
       "       [-0.16703106,  0.14468575],\n",
       "       [-0.16703054,  0.14468601],\n",
       "       [-0.16703096,  0.14468575],\n",
       "       [-0.16703121,  0.14468598],\n",
       "       [-0.16703077,  0.14468555],\n",
       "       [-0.16703065,  0.14468563],\n",
       "       [-0.1670308 ,  0.14468548],\n",
       "       [-0.1670308 ,  0.14468592],\n",
       "       [-0.16703095,  0.14468588],\n",
       "       [-0.16703047,  0.14468625],\n",
       "       [-0.16703074,  0.14468607],\n",
       "       [-0.16703051,  0.14468612],\n",
       "       [-0.16703078,  0.14468567],\n",
       "       [-0.16703083,  0.14468569],\n",
       "       [-0.16703065,  0.14468601],\n",
       "       [-0.16703017,  0.14468592],\n",
       "       [-0.1670306 ,  0.14468592],\n",
       "       [-0.16703023,  0.1446856 ],\n",
       "       [-0.1670302 ,  0.14468633],\n",
       "       [-0.1670308 ,  0.14468604],\n",
       "       [-0.16703084,  0.14468546],\n",
       "       [-0.16703025,  0.14468637],\n",
       "       [-0.16703053,  0.1446856 ],\n",
       "       [-0.16703026,  0.1446861 ],\n",
       "       [-0.16703051,  0.14468563],\n",
       "       [-0.16703057,  0.14468622],\n",
       "       [-0.16703089,  0.14468558],\n",
       "       [-0.16703068,  0.14468601],\n",
       "       [-0.16703083,  0.1446854 ],\n",
       "       [-0.16703074,  0.14468591],\n",
       "       [-0.16703032,  0.14468506],\n",
       "       [-0.16703089,  0.1446859 ],\n",
       "       [-0.16703089,  0.14468572],\n",
       "       [-0.16703095,  0.14468598],\n",
       "       [-0.16703069,  0.14468558],\n",
       "       [-0.16703044,  0.14468578],\n",
       "       [-0.16703066,  0.14468548],\n",
       "       [-0.1670305 ,  0.1446858 ],\n",
       "       [-0.16703105,  0.14468533],\n",
       "       [-0.16703065,  0.14468619],\n",
       "       [-0.1670308 ,  0.14468615],\n",
       "       [-0.16703068,  0.1446858 ],\n",
       "       [-0.16703077,  0.14468592],\n",
       "       [-0.16703078,  0.14468566],\n",
       "       [-0.16703075,  0.14468595],\n",
       "       [-0.16703057,  0.14468597],\n",
       "       [-0.16703083,  0.14468598],\n",
       "       [-0.16703027,  0.14468619],\n",
       "       [-0.16703089,  0.14468601],\n",
       "       [-0.167031  ,  0.14468607],\n",
       "       [-0.16703092,  0.14468586],\n",
       "       [-0.16703095,  0.1446859 ],\n",
       "       [-0.167031  ,  0.14468616],\n",
       "       [-0.16703032,  0.14468597],\n",
       "       [-0.16703032,  0.14468622],\n",
       "       [-0.16703065,  0.14468575],\n",
       "       [-0.1670305 ,  0.1446864 ],\n",
       "       [-0.16703074,  0.14468572],\n",
       "       [-0.16703118,  0.14468557],\n",
       "       [-0.16703089,  0.1446858 ],\n",
       "       [-0.16703002,  0.14468604],\n",
       "       [-0.16703029,  0.14468591],\n",
       "       [-0.16703095,  0.14468534],\n",
       "       [-0.16703053,  0.14468588],\n",
       "       [-0.16703098,  0.1446859 ],\n",
       "       [-0.16703075,  0.14468534],\n",
       "       [-0.16703102,  0.14468569],\n",
       "       [-0.16703066,  0.1446861 ],\n",
       "       [-0.16703053,  0.14468631],\n",
       "       [-0.16703026,  0.14468588],\n",
       "       [-0.16703115,  0.14468557],\n",
       "       [-0.1670299 ,  0.14468622],\n",
       "       [-0.16703029,  0.14468616],\n",
       "       [-0.16703099,  0.14468566],\n",
       "       [-0.16703047,  0.1446855 ],\n",
       "       [-0.1670308 ,  0.14468548],\n",
       "       [-0.1670305 ,  0.14468622],\n",
       "       [-0.16703126,  0.14468528],\n",
       "       [-0.16703042,  0.14468634],\n",
       "       [-0.16703072,  0.14468566],\n",
       "       [-0.16703022,  0.14468607],\n",
       "       [-0.16703057,  0.144686  ],\n",
       "       [-0.16703065,  0.14468588],\n",
       "       [-0.16703044,  0.14468622],\n",
       "       [-0.1670304 ,  0.14468572],\n",
       "       [-0.16703087,  0.14468586],\n",
       "       [-0.16703068,  0.14468595],\n",
       "       [-0.1670305 ,  0.14468607],\n",
       "       [-0.1670307 ,  0.14468603],\n",
       "       [-0.1670305 ,  0.14468631],\n",
       "       [-0.16703074,  0.14468524],\n",
       "       [-0.16703027,  0.14468591],\n",
       "       [-0.16703008,  0.14468569],\n",
       "       [-0.16703103,  0.14468545],\n",
       "       [-0.16703066,  0.14468609],\n",
       "       [-0.16703029,  0.1446867 ],\n",
       "       [-0.16703095,  0.14468572],\n",
       "       [-0.16703089,  0.14468566],\n",
       "       [-0.16703047,  0.14468557],\n",
       "       [-0.16703092,  0.14468576],\n",
       "       [-0.16703117,  0.14468572],\n",
       "       [-0.16703069,  0.1446857 ],\n",
       "       [-0.1670307 ,  0.14468597],\n",
       "       [-0.16703062,  0.14468628],\n",
       "       [-0.16703014,  0.14468612],\n",
       "       [-0.1670313 ,  0.14468521],\n",
       "       [-0.1670304 ,  0.14468622],\n",
       "       [-0.16703069,  0.14468598],\n",
       "       [-0.16703133,  0.14468578],\n",
       "       [-0.16703103,  0.14468563],\n",
       "       [-0.16703059,  0.14468597],\n",
       "       [-0.16703074,  0.14468579],\n",
       "       [-0.16703086,  0.14468595],\n",
       "       [-0.16703068,  0.14468598],\n",
       "       [-0.16703096,  0.14468592],\n",
       "       [-0.16703072,  0.14468613],\n",
       "       [-0.16703008,  0.14468539],\n",
       "       [-0.1670307 ,  0.14468557],\n",
       "       [-0.16703075,  0.14468575],\n",
       "       [-0.16703029,  0.14468601],\n",
       "       [-0.16703093,  0.14468578],\n",
       "       [-0.1670308 ,  0.14468586],\n",
       "       [-0.16703051,  0.14468586],\n",
       "       [-0.16703014,  0.1446859 ],\n",
       "       [-0.16703069,  0.14468575],\n",
       "       [-0.16703083,  0.14468625],\n",
       "       [-0.16703126,  0.1446853 ],\n",
       "       [-0.16702996,  0.14468628],\n",
       "       [-0.16703005,  0.14468504],\n",
       "       [-0.1670307 ,  0.14468585],\n",
       "       [-0.1670306 ,  0.14468592],\n",
       "       [-0.16703062,  0.14468586],\n",
       "       [-0.16703127,  0.14468543],\n",
       "       [-0.16703066,  0.1446856 ],\n",
       "       [-0.16703068,  0.14468618],\n",
       "       [-0.16703077,  0.14468628],\n",
       "       [-0.16703084,  0.14468595],\n",
       "       [-0.16703078,  0.14468558],\n",
       "       [-0.16703023,  0.14468598],\n",
       "       [-0.1670306 ,  0.144686  ],\n",
       "       [-0.1670311 ,  0.14468625],\n",
       "       [-0.16703115,  0.14468518],\n",
       "       [-0.16703075,  0.14468585],\n",
       "       [-0.16703054,  0.14468569],\n",
       "       [-0.16703112,  0.1446859 ],\n",
       "       [-0.16703057,  0.14468619],\n",
       "       [-0.16703011,  0.14468616],\n",
       "       [-0.16703063,  0.1446861 ],\n",
       "       [-0.1670304 ,  0.14468594],\n",
       "       [-0.16703045,  0.14468609],\n",
       "       [-0.16703054,  0.14468607],\n",
       "       [-0.16703065,  0.14468572],\n",
       "       [-0.16703068,  0.14468582],\n",
       "       [-0.16702978,  0.14468601],\n",
       "       [-0.16703038,  0.14468607],\n",
       "       [-0.16703056,  0.14468572]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Can a federal district court conduct an independent review of the evidence of a state court’s finding of a constitutional aggravating circumstance?\n",
      "Did Arizona’s construction of the “especially heinous…or depraved” aggravating circumstance contravene Supreme Court precedent? [SEP] In May of 1976, Jimmy Wayne defendant and his girlfriend, Penelope Cheney, were arrested for possession of narcotics and receipt of stolen property. defendant posted bond for Cheney but was unable to post bond for himself. While in jail, defendant learned that Cheney was cooperating with the police. He offered another inmate money to kill Cheney, but a detention officer seized the note. defendant was released on bond in October of 1976. He quickly contacted Cheney and invited her to his motel room to give her heroin. When Doris Van der Veer, the woman with whom defendant had been living since his release from prison, entered the room a few hours later, she saw Cheney comatose on the bed and defendant injecting liquid into her arm. Van der Veer reported seeing defendant choke Cheney to death and then beat her body while calling her dirty names. Van der Veer and defendant then wrapped the body in newspapers and plastic bags and buried it in a shallow grave.\n",
      "A jury convicted defendant of first-degree murder. At sentencing, the court found two aggravating circumstances and no mitigating factors, so defendant was sentenced to death under Arizona state law. On direct review, the Arizona Supreme Court vacated the death sentence and remanded the case for resentencing. On a second direct appeal, the Arizona Supreme Court conducted an independent review of the evidence and affirmed the death sentence. defendant petitioned the district court for a writ of habeas corpus and argued that Arizona’s standard of an “especially heinous…or depraved” aggravating circumstance was unconstitutionally vague. The district court rejected defendant’ challenge. The U.S. Court of Appeals for the Ninth Circuit held that the standard was unconstitutionally vague as it applied to defendant and struck down the death sentence.\n",
      " \n",
      "\n",
      "Tokenized:  ['[CLS]', 'can', 'a', 'federal', 'district', 'court', 'conduct', 'an', 'independent', 'review', 'of', 'the', 'evidence', 'of', 'a', 'state', 'court', '[UNK]', 's', 'finding', 'of', 'a', 'constitutional', 'aggravating', 'circumstance', '?', 'did', 'arizona', '[UNK]', 's', 'construction', 'of', 'the', '[UNK]', 'especially', 'he', '##inous', '[UNK]', 'or', 'dep', '##rave', '##d', '[UNK]', 'aggravating', 'circumstance', 'contravene', 'supreme', 'court', 'precedent', '?', '[SEP]', 'in', 'may', 'of', '1976', ',', 'jim', '##m', '##y', 'wayne', 'defendant', 'and', 'his', 'girl', '##friend', ',', 'pen', '##elop', '##e', 'chen', '##e', '##y', ',', 'were', 'arrested', 'for', 'possession', 'of', 'narcotic', '##s', 'and', 'receipt', 'of', 'stolen', 'property', '.', 'defendant', 'posted', 'bond', 'for', 'chen', '##e', '##y', 'but', 'was', 'unable', 'to', 'post', 'bond', 'for', 'himself', '.', 'while', 'in', 'jail', ',', 'defendant', 'learned', 'that', 'chen', '##e', '##y', 'was', 'cooperat', '##ing', 'with', 'the', 'police', '.', 'he', 'offered', 'another', 'inmate', 'money', 'to', 'kill', 'chen', '##e', '##y', ',', 'but', 'a', 'detention', 'officer', 'seized', 'the', 'note', '.', 'defendant', 'was', 'released', 'on', 'bond', 'in', 'october', 'of', '1976', '.', 'he', 'quick', '##ly', 'contacted', 'chen', '##e', '##y', 'and', 'invited', 'her', 'to', 'his', 'motel', 'room', 'to', 'give', 'her', 'heroin', '.', 'when', 'doris', 'van', 'de', '##r', 'v', '##e', '##er', ',', 'the', 'woman', 'with', 'whom', 'defendant', 'had', 'been', 'living', 'since', 'his', 'release', 'from', 'prison', ',', 'entered', 'the', 'room', 'a', 'few', 'hours', 'later', ',', 'she', 'saw', 'chen', '##e', '##y', 'com', '##at', '##ose', 'on', 'the', 'be', '##d', 'and', 'defendant', 'inject', '##ing', 'liquid', 'into', 'her', 'arm', '.', 'van', 'de', '##r', 'v', '##e', '##er', 'reported', 'see', '##ing', 'defendant', 'cho', '##ke', 'chen', '##e', '##y', 'to', 'death', 'and', 'the', '##n', 'be', '##at', 'her', 'body', 'while', 'calling', 'her', 'dirty', 'names', '.', 'van', 'de', '##r', 'v', '##e', '##er', 'and', 'defendant', 'the', '##n', 'wrapp', '##ed', 'the', 'body', 'in', 'newspapers', 'and', 'plastic', 'bag', '##s', 'and', 'burie', '##d', 'it', 'in', 'a', 'shall', '##ow', 'grave', '.', 'a', 'jury', 'convicted', 'defendant', 'of', 'first', '-', 'degree', 'murder', '.', 'at', 'sentencing', ',', 'the', 'court', 'found', 'two', 'aggravating', 'circumstances', 'and', 'no', 'mitigating', 'factors', ',', 'so', 'defendant', 'was', 'sentenced', 'to', 'death', 'under', 'arizona', 'state', 'law', '.', 'on', 'direct', 'review', ',', 'the', 'arizona', 'supreme', 'court', 'vacated', 'the', 'death', 'sentence', 'and', 'remanded', 'the', 'case', 'for', 'resentencing', '.', 'on', 'a', 'second', 'direct', 'appeal', ',', 'the', 'arizona', 'supreme', 'court', 'conducted', 'an', 'independent', 'review', 'of', 'the', 'evidence', 'and', 'affirmed', 'the', 'death', 'sentence', '.', 'defendant', 'petition', '##ed', 'the', 'district', 'court', 'for', 'a', 'writ', 'of', 'habeas', 'corpus', 'and', 'argued', 'that', 'arizona', '[UNK]', 's', 'standard', 'of', 'an', '[UNK]', 'especially', 'he', '##inous', '[UNK]', 'or', 'dep', '##rave', '##d', '[UNK]', 'aggravating', 'circumstance', 'was', 'uncon', '##stitut', '##ional', '##ly', 'vague', '.', 'the', 'district', 'court', 'rejected', 'defendant', '[UNK]', 'challenge', '.', 'the', 'u', '.', 's', '.', 'court', 'of', 'appeals', 'for', 'the', 'ninth', 'circuit', 'held', 'that', 'the', 'standard', 'was', 'uncon', '##stitut', '##ional', '##ly', 'vague', 'as', 'it', 'applied', 'to', 'defendant', 'and', 'struck', 'down', 'the', 'death', 'sentence', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Token IDs:  [101, 356, 145, 522, 483, 240, 818, 237, 972, 709, 210, 207, 460, 210, 145, 264, 240, 100, 163, 1408, 210, 145, 1515, 10364, 3591, 124, 503, 6221, 100, 163, 1134, 210, 207, 100, 2872, 300, 7593, 100, 215, 4441, 21961, 174, 100, 10364, 3591, 7927, 1313, 240, 2607, 124, 102, 213, 245, 210, 2379, 115, 12018, 183, 195, 11045, 588, 212, 275, 5751, 15676, 115, 6580, 27983, 175, 7911, 175, 195, 115, 292, 3824, 217, 1470, 210, 8286, 189, 212, 806, 210, 5442, 359, 117, 588, 6269, 2233, 217, 7911, 175, 195, 310, 246, 2159, 211, 1273, 2233, 217, 2744, 117, 934, 213, 8276, 115, 588, 6532, 216, 7911, 175, 195, 246, 4765, 235, 225, 207, 1145, 117, 300, 1661, 789, 6988, 1364, 211, 9983, 7911, 175, 195, 115, 310, 145, 976, 714, 6036, 207, 499, 117, 588, 246, 1889, 222, 2233, 213, 647, 210, 2379, 117, 300, 4805, 301, 7287, 7911, 175, 195, 212, 4426, 502, 211, 275, 20014, 3362, 211, 851, 502, 11415, 117, 372, 27135, 2109, 406, 188, 166, 175, 577, 115, 207, 7076, 225, 1784, 588, 263, 255, 3060, 626, 275, 815, 238, 1895, 115, 835, 207, 3362, 145, 3425, 1705, 983, 115, 741, 4445, 7911, 175, 195, 1871, 2272, 5267, 222, 207, 219, 174, 212, 588, 17698, 235, 2098, 288, 502, 3659, 117, 2109, 406, 188, 166, 175, 577, 1905, 321, 235, 588, 9735, 5907, 7911, 175, 195, 211, 1466, 212, 207, 184, 219, 2272, 502, 1207, 934, 6552, 502, 19566, 2302, 117, 2109, 406, 188, 166, 175, 577, 212, 588, 207, 184, 11609, 252, 207, 1207, 213, 8282, 212, 3349, 4052, 189, 212, 21737, 174, 233, 213, 145, 224, 5750, 7883, 117, 145, 1336, 3276, 588, 210, 296, 116, 2030, 4127, 117, 236, 3334, 115, 207, 240, 765, 428, 10364, 620, 212, 230, 8603, 1674, 115, 340, 588, 246, 4205, 211, 1466, 242, 6221, 264, 266, 117, 222, 830, 709, 115, 207, 6221, 1313, 240, 6672, 207, 1466, 1091, 212, 5661, 207, 256, 217, 18172, 117, 222, 145, 450, 830, 615, 115, 207, 6221, 1313, 240, 1537, 237, 972, 709, 210, 207, 460, 212, 3382, 207, 1466, 1091, 117, 588, 1497, 252, 207, 483, 240, 217, 145, 3858, 210, 4755, 5703, 212, 1785, 216, 6221, 100, 163, 847, 210, 237, 100, 2872, 300, 7593, 100, 215, 4441, 21961, 174, 100, 10364, 3591, 246, 23287, 18487, 20393, 301, 7640, 117, 207, 483, 240, 1653, 588, 100, 2533, 117, 207, 165, 117, 163, 117, 240, 210, 1409, 217, 207, 4201, 881, 545, 216, 207, 847, 246, 23287, 18487, 20393, 301, 7640, 221, 233, 740, 211, 588, 212, 6874, 476, 207, 1466, 1091, 117, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "\n",
    "# Print the original sentence.\n",
    "print('Original: ', dataset[\"train\"][idx][\"text\"])\n",
    "print()\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(dataset[\"train\"][idx][\"text\"], padding=\"max_length\", truncation=True, max_length=512, add_special_tokens=True))\n",
    "print()\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(dataset[\"train\"][idx][\"text\"], padding=\"max_length\", truncation=True, max_length=512, add_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bcfee793e6c521d527cbdd180a6b57828f21de8e1d26510d562b2b26b0dd756"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('scotus': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
