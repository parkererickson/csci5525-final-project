{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "import pyTigerGraph as tg \n",
    "import pandas as pd\n",
    "conn = tg.TigerGraphConnection(graphname=\"SCOTUS_Graph\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "res = conn.runInstalledQuery(\"justiceCaseLinks\", params={\"justiceID\": 105})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "res[0][\"@@justiceEmbedding\"].keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['AScalia'])"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "caseEmbeddings = res[0][\"@@caseEmbeddings\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "caseVotes = pd.DataFrame.from_dict(res[0][\"@@caseVote\"], orient=\"index\").reset_index().rename(columns={\"index\":\"caseId\", 0:\"vote\"})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "caseVotes[\"vote\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "VOTED_IN_FAVOR_OF_PLAINTIFF    1781\n",
       "VOTED_IN_FAVOR_OF_DEFENDANT    1080\n",
       "Name: vote, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "caseEmbeddings = pd.DataFrame.from_dict(caseEmbeddings, orient=\"index\").reset_index().rename(columns={\"index\":\"caseId\"})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "data = caseVotes.merge(caseEmbeddings, on=\"caseId\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "X = data[[i for i in range(0, 200)]]\n",
    "data[\"vote\"] = data[\"vote\"].astype(\"category\")\n",
    "data[\"vote_code\"] = data[\"vote\"].cat.codes\n",
    "y = data[\"vote_code\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "data[\"vote\"].head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    VOTED_IN_FAVOR_OF_PLAINTIFF\n",
       "1    VOTED_IN_FAVOR_OF_PLAINTIFF\n",
       "2    VOTED_IN_FAVOR_OF_PLAINTIFF\n",
       "3    VOTED_IN_FAVOR_OF_PLAINTIFF\n",
       "4    VOTED_IN_FAVOR_OF_PLAINTIFF\n",
       "Name: vote, dtype: category\n",
       "Categories (2, object): ['VOTED_IN_FAVOR_OF_DEFENDANT', 'VOTED_IN_FAVOR_OF_PLAINTIFF']"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "data[\"vote\"].cat.codes.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "dtype: int8"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf = LogisticRegression(class_weight=\"balanced\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(classification_report(y_test, clf.predict(X_test), target_names=[\"Defendant\", \"Plaintiff\"]))\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Defendant       0.44      0.62      0.52       217\n",
      "   Plaintiff       0.69      0.53      0.60       356\n",
      "\n",
      "    accuracy                           0.56       573\n",
      "   macro avg       0.57      0.57      0.56       573\n",
      "weighted avg       0.60      0.56      0.57       573\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('scotus': conda)"
  },
  "interpreter": {
   "hash": "c7d6c6bf3a9871602155f511049beaabedd6a9be8dcd8fb85b899fcd7dc30501"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}